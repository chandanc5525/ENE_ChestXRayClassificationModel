{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c421219",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# MODEL TRAINING AND EVALUATION NOTEBOOK\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# ============================================================\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# STEP 1: Import Dependencies\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01myaml\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'yaml'"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# MODEL TRAINING AND EVALUATION NOTEBOOK\n",
    "# ============================================================\n",
    "\n",
    "# STEP 1: Import Dependencies\n",
    "import os\n",
    "import yaml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16, EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# ============================================================\n",
    "# STEP 2: Load Configurations\n",
    "# ============================================================\n",
    "\n",
    "with open(\"../config/config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "base_path = config[\"data\"][\"base_path\"]\n",
    "image_size = tuple(config[\"data\"][\"image_size\"])\n",
    "batch_size = config[\"data\"][\"batch_size\"]\n",
    "epochs = 10\n",
    "lr = config[\"model\"][\"learning_rate\"]\n",
    "dropout = config[\"model\"][\"dropout\"]\n",
    "\n",
    "print(\"Configuration loaded successfully.\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 3: Prepare Data Generators (All in Grayscale)\n",
    "# ============================================================\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    os.path.join(base_path, \"train\"),\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    os.path.join(base_path, \"val\"),\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"binary\"\n",
    ")\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    os.path.join(base_path, \"test\"),\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=\"binary\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"Data generators ready.\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 4: Define Model Architectures\n",
    "# ============================================================\n",
    "\n",
    "def build_simple_cnn(input_shape=(180,180,1), dropout=0.3, lr=0.001):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "        layers.Conv2D(64, (3,3), activation='relu'),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "        layers.Conv2D(128, (3,3), activation='relu'),\n",
    "        layers.MaxPooling2D(2,2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(dropout),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_vgg16_model(input_shape=(180,180,1), dropout=0.3, lr=0.001):\n",
    "    # Convert grayscale to 3 channels for pretrained model\n",
    "    base = VGG16(weights='imagenet', include_top=False, input_shape=(180,180,3))\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base.input, outputs=output)\n",
    "    for layer in base.layers[:-4]:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_efficientnet_model(input_shape=(180,180,3), dropout=0.3, lr=0.001):\n",
    "    base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    x = layers.GlobalAveragePooling2D()(base.output)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=base.input, outputs=output)\n",
    "    for layer in base.layers[:-5]:\n",
    "        layer.trainable = False\n",
    "    model.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# ============================================================\n",
    "# STEP 5: Train Models\n",
    "# ============================================================\n",
    "\n",
    "models_dict = {\n",
    "    \"SimpleCNN\": build_simple_cnn(),\n",
    "    \"VGG16\": build_vgg16_model(),\n",
    "    \"EfficientNetB0\": build_efficientnet_model()\n",
    "}\n",
    "\n",
    "histories = {}\n",
    "results = {}\n",
    "\n",
    "for name, model in models_dict.items():\n",
    "    print(f\"\\nTraining {name} ...\")\n",
    "    if name == \"SimpleCNN\":\n",
    "        history = model.fit(train_gen, validation_data=val_gen, epochs=epochs)\n",
    "    else:\n",
    "        # Convert grayscale to RGB for pretrained models\n",
    "        rgb_train = ImageDataGenerator(rescale=1.0/255).flow_from_directory(\n",
    "            os.path.join(base_path, \"train\"),\n",
    "            target_size=image_size,\n",
    "            batch_size=batch_size,\n",
    "            color_mode=\"rgb\",\n",
    "            class_mode=\"binary\"\n",
    "        )\n",
    "        rgb_val = ImageDataGenerator(rescale=1.0/255).flow_from_directory(\n",
    "            os.path.join(base_path, \"val\"),\n",
    "            target_size=image_size,\n",
    "            batch_size=batch_size,\n",
    "            color_mode=\"rgb\",\n",
    "            class_mode=\"binary\"\n",
    "        )\n",
    "        history = model.fit(rgb_train, validation_data=rgb_val, epochs=epochs)\n",
    "\n",
    "    histories[name] = history\n",
    "    loss, acc = model.evaluate(test_gen)\n",
    "    results[name] = acc\n",
    "    print(f\"{name} Test Accuracy: {acc:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# STEP 6: Compare Model Performance\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nModel Accuracy Comparison:\")\n",
    "for name, acc in results.items():\n",
    "    print(f\"{name}: {acc:.4f}\")\n",
    "\n",
    "# Plot accuracy and loss curves\n",
    "plt.figure(figsize=(12, 6))\n",
    "for name, hist in histories.items():\n",
    "    plt.plot(hist.history['accuracy'], label=f'{name} Train Acc')\n",
    "    plt.plot(hist.history['val_accuracy'], label=f'{name} Val Acc')\n",
    "plt.title('Model Accuracy Comparison')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "for name, hist in histories.items():\n",
    "    plt.plot(hist.history['loss'], label=f'{name} Train Loss')\n",
    "    plt.plot(hist.history['val_loss'], label=f'{name} Val Loss')\n",
    "plt.title('Model Loss Comparison')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# ============================================================\n",
    "# STEP 7: Evaluate Best Model\n",
    "# ============================================================\n",
    "\n",
    "best_model_name = max(results, key=results.get)\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "\n",
    "best_model = models_dict[best_model_name]\n",
    "pred = (best_model.predict(test_gen) > 0.5).astype(\"int32\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(test_gen.classes, pred))\n",
    "\n",
    "cm = confusion_matrix(test_gen.classes, pred)\n",
    "plt.figure(figsize=(5,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(f'{best_model_name} Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
